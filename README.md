# **CEIA - FIUBA**

>**Facultad de IngenierÃ­a (Universidad de Buenos Aires)**

>**EspecializaciÃ³n en Inteligencia Artificial**
---
# **Procesamiento de Lenguaje Natural I**

---

### **Alumno**
>**Nicolas Pinzon Aparicio**  
>**(a1820)**  
>**npinzonaparicio@gmail.com**

---

## **Contenido del repositorio**

Este repositorio contiene los notebooks desarrollados como parte de la materia **Procesamiento de Lenguaje Natural I**, organizados en cuatro desafÃ­os principales que cubren desde tÃ©cnicas fundamentales hasta modelos avanzados de deep learning.

---

## **DesafÃ­os**

| Notebook | TemÃ¡tica Principal | DescripciÃ³n |
|----------|-------------------|-------------|
| **Desafio_1.ipynb** | **VectorizaciÃ³n de Texto y ClasificaciÃ³n NaÃ¯ve Bayes** | AnÃ¡lisis del dataset 20 Newsgroups mediante vectorizaciÃ³n TF-IDF, estudio de similaridad coseno entre documentos, y entrenamiento de clasificadores NaÃ¯ve Bayes (Multinomial y Complement) con optimizaciÃ³n de hiperparÃ¡metros. Incluye anÃ¡lisis de similaridad entre palabras usando matrices tÃ©rmino-documento. |
| **2c - Custom embedding con Gensim.ipynb** | **Word Embeddings Personalizados con Gensim** | CreaciÃ³n de embeddings customizados usando Word2Vec sobre un corpus musical de mÃºltiples artistas (Beatles, Bob Dylan, Nirvana, Radiohead, Drake). ExploraciÃ³n de relaciones semÃ¡nticas, visualizaciÃ³n 2D/3D con t-SNE y PCA, y anÃ¡lisis de clusters temÃ¡ticos. |
| **3_modelo_lenguaje_word.ipynb** | **Modelo de Lenguaje con TokenizaciÃ³n por Palabras** | ImplementaciÃ³n de un modelo de lenguaje usando arquitecturas RNN (SimpleRNN, LSTM, GRU) entrenado en letras de canciones. Incluye generaciÃ³n de texto con estrategias Greedy Search, Beam Search y muestreo por temperatura. Monitoreo con callback de perplejidad. |
| **6- bot_qa.ipynb** | **Bot de Pregunta-Respuesta (QA Bot)** | Desarrollo de un chatbot usando arquitectura Encoder-Decoder con LSTM entrenado en el dataset ConvAI2. ImplementaciÃ³n de modelos de inferencia separados y evaluaciÃ³n interactiva del bot con mÃºltiples estrategias de generaciÃ³n de respuestas. |

---

## **âš™ï¸ Requisitos tÃ©cnicos**

### **Dependencias principales**
```bash
pip install tensorflow>=2.19.0
pip install scikit-learn>=1.6.0
pip install gensim>=4.3.0
pip install pandas numpy matplotlib seaborn
pip install plotly gdown nltk
```

### **Entorno recomendado**
- Python 3.9+
- Jupyter Notebook o Google Colab
- MÃ­nimo 8GB RAM para entrenamiento de modelos

---

## **ğŸš€ CaracterÃ­sticas destacadas**

### **DesafÃ­o 1: AnÃ¡lisis Textual Avanzado**
- âœ… VectorizaciÃ³n TF-IDF con optimizaciÃ³n de hiperparÃ¡metros
- âœ… ComparaciÃ³n de modelos MultinomialNB vs ComplementNB
- âœ… AnÃ¡lisis de similaridad documento-documento y palabra-palabra
- âœ… F1-score macro de 0.7078 en el mejor modelo

### **DesafÃ­o 2: Embeddings Musicales**
- âœ… Corpus rico de 16,160 lÃ­neas de 5 artistas diversos
- âœ… Word2Vec entrenado por 50 Ã©pocas con vocabulario de 2,947 palabras
- âœ… Visualizaciones interactivas con Plotly
- âœ… AnÃ¡lisis semÃ¡ntico por categorÃ­as (emociones, mÃºsica, tiempo, personas)

### **DesafÃ­o 3: GeneraciÃ³n de Texto Musical**
- âœ… Modelo LSTM optimizado con 1.37M parÃ¡metros
- âœ… Corpus de 10,710 lÃ­neas con vocabulario de 6,259 palabras
- âœ… MÃºltiples estrategias de generaciÃ³n (Greedy, Beam Search, Temperatura)
- âœ… Callback personalizado para monitoreo de perplejidad

### **DesafÃ­o 4: Chatbot Conversacional**
- âœ… Arquitectura Encoder-Decoder con embeddings compartidos
- âœ… Dataset ConvAI2 con 8,870 pares pregunta-respuesta
- âœ… Modelos de inferencia optimizados para deployment
- âœ… EvaluaciÃ³n interactiva con chat en tiempo real

---

## **ğŸ“Š Resultados obtenidos**

| DesafÃ­o | MÃ©trica Principal | Resultado | Observaciones |
|---------|------------------|-----------|---------------|
| 1 | F1-score macro | **0.7078** | ComplementNB superÃ³ a MultinomialNB |
| 2 | Coherencia semÃ¡ntica | **Alta** | Clusters temÃ¡ticos bien definidos |
| 3 | Perplejidad final | **298.41** | GeneraciÃ³n coherente a nivel local |
| 4 | Accuracy validaciÃ³n | **0.2654** | Bot funcional para conversaciones bÃ¡sicas |

---

## **ğŸ¯ Uso de los notebooks**

### **Para ejecutar individualmente:**
```python
# DesafÃ­o 1 - ClasificaciÃ³n
from sklearn.naive_bayes import ComplementNB
from sklearn.feature_extraction.text import TfidfVectorizer

# DesafÃ­o 2 - Word2Vec
from gensim.models import Word2Vec
model.wv.most_similar('love', topn=5)

# DesafÃ­o 3 - GeneraciÃ³n de texto
generate_text_with_temperature(model, tokenizer, "love is", max_length=10, temperature=1.0)

# DesafÃ­o 4 - QA Bot
response = generate_response("How are you?")
```

### **Para chat interactivo (DesafÃ­o 4):**
```python
chat_with_bot()  # Inicia sesiÃ³n de chat
```

---

## **ğŸ“ Estructura del proyecto**

```
â”œâ”€â”€ Desafio_1.ipynb                                   # VectorizaciÃ³n y NaÃ¯ve Bayes
â”œâ”€â”€ 2c - Custom embedding con Gensim.ipynb            # Word Embeddings con Gensim  
â”œâ”€â”€ 3_modelo_lenguaje_word.ipynb                      # Modelo de lenguaje RNN
â”œâ”€â”€ 6- bot_qa.ipynb                                   # QA Bot Seq2Seq

```

---

## **ğŸ”¬ MetodologÃ­a aplicada**

Cada desafÃ­o sigue una metodologÃ­a rigurosa:

1. **AnÃ¡lisis exploratorio** detallado de los datos
2. **Preprocesamiento** especÃ­fico para cada tarea
3. **ExperimentaciÃ³n** con mÃºltiples arquitecturas/parÃ¡metros
4. **EvaluaciÃ³n cuantitativa** con mÃ©tricas apropiadas
5. **AnÃ¡lisis cualitativo** de resultados generados
6. **DocumentaciÃ³n completa** de conclusiones y limitaciones

---

## **ğŸ’¡ Contribuciones tÃ©cnicas**

- **Callbacks personalizados** para monitoreo de perplejidad
- **Visualizaciones interactivas** con Plotly para embeddings
- **Estrategias avanzadas** de generaciÃ³n de texto (Beam Search estocÃ¡stico)
- **Arquitecturas optimizadas** para recursos limitados
- **EvaluaciÃ³n integral** combinando mÃ©tricas automÃ¡ticas y anÃ¡lisis humano


---

*Desarrollado como parte del posgrado en Inteligencia Artificial - FIUBA 2025*